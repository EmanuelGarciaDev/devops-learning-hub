{
  "id": "marketplace",
  "toolId": "github-actions",
  "name": "Actions Marketplace",
  "description": "Explore, create, and publish custom GitHub Actions to the marketplace ecosystem for advanced automation and community sharing",
  "difficulty": "advanced",
  "definitions": {
    "beginner": "The GitHub Actions Marketplace is a hub where you can find thousands of pre-built actions created by the community, and also publish your own custom actions for others to use in their workflows.",
    "advanced": "The Actions Marketplace ecosystem enables sophisticated automation through composite actions, Docker container actions, and JavaScript actions with advanced features like custom branding, versioning strategies, action metadata, and comprehensive testing frameworks for enterprise-grade action development and distribution."
  },
  "commands": [
    {
      "command": "gh extension install",
      "description": "Install GitHub CLI extensions for action development",
      "example": "gh extension install github/gh-actions-cache",
      "flags": [
        {
          "flag": "--force",
          "description": "Force installation over existing",
          "example": "--force"
        },
        {
          "flag": "--pin",
          "description": "Pin to specific version",
          "example": "--pin v1.0.0"
        }
      ]
    },
    {
      "command": "gh actions-importer",
      "description": "Migrate workflows from other CI/CD platforms",
      "example": "gh actions-importer audit jenkins",
      "flags": [
        {
          "flag": "--output-dir",
          "description": "Output directory for migrated workflows",
          "example": "--output-dir ./migrated"
        },
        {
          "flag": "--source-url",
          "description": "Source system URL",
          "example": "--source-url https://jenkins.example.com"
        }
      ]
    },
    {
      "command": "action.yml",
      "description": "Define action metadata and interface",
      "example": "name: 'My Custom Action'",
      "flags": [
        {
          "flag": "name",
          "description": "Action name",
          "example": "name: 'Deploy to AWS'"
        },
        {
          "flag": "description",
          "description": "Action description",
          "example": "description: 'Deploy application to AWS'"
        },
        {
          "flag": "inputs",
          "description": "Define action inputs",
          "example": "inputs: { aws-region: { required: true } }"
        },
        {
          "flag": "outputs",
          "description": "Define action outputs",
          "example": "outputs: { deployment-url: { description: 'URL' } }"
        },
        {
          "flag": "runs",
          "description": "Specify how action runs",
          "example": "runs: { using: 'node16', main: 'index.js' }"
        }
      ]
    },
    {
      "command": "docker build",
      "description": "Build Docker container for Docker-based actions",
      "example": "docker build -t my-action .",
      "flags": [
        {
          "flag": "-f",
          "description": "Dockerfile path",
          "example": "-f Dockerfile.action"
        },
        {
          "flag": "--platform",
          "description": "Target platform",
          "example": "--platform linux/amd64"
        },
        {
          "flag": "--build-arg",
          "description": "Build arguments",
          "example": "--build-arg NODE_VERSION=18"
        }
      ]
    }
  ],
  "examples": [
    {
      "title": "Creating a JavaScript Action",
      "description": "Complete JavaScript action with TypeScript, testing, and marketplace publishing",
      "code": "# JavaScript Action Development\n# Complete setup for a production-ready action\n\n# 1. Action Metadata (action.yml)\nname: 'AWS S3 Deploy'\ndescription: 'Deploy static files to AWS S3 with CloudFront invalidation'\nauthor: 'Your Name'\nbranding:\n  icon: 'upload-cloud'\n  color: 'orange'\n\ninputs:\n  aws-access-key-id:\n    description: 'AWS Access Key ID'\n    required: true\n  \n  aws-secret-access-key:\n    description: 'AWS Secret Access Key'\n    required: true\n  \n  aws-region:\n    description: 'AWS Region'\n    required: true\n    default: 'us-east-1'\n  \n  s3-bucket:\n    description: 'S3 bucket name'\n    required: true\n  \n  source-dir:\n    description: 'Source directory to upload'\n    required: true\n    default: './dist'\n  \n  cloudfront-distribution-id:\n    description: 'CloudFront distribution ID for invalidation'\n    required: false\n  \n  cache-control:\n    description: 'Cache-Control header value'\n    required: false\n    default: 'public, max-age=3600'\n  \n  exclude-patterns:\n    description: 'Patterns to exclude from upload (newline-separated)'\n    required: false\n  \n  dry-run:\n    description: 'Preview changes without uploading'\n    required: false\n    default: 'false'\n\noutputs:\n  uploaded-files:\n    description: 'Number of files uploaded'\n  \n  s3-url:\n    description: 'S3 bucket URL'\n  \n  cloudfront-url:\n    description: 'CloudFront distribution URL'\n  \n  invalidation-id:\n    description: 'CloudFront invalidation ID'\n\nruns:\n  using: 'node16'\n  main: 'dist/index.js'\n\n---\n\n# 2. Package.json Configuration\n{\n  \"name\": \"aws-s3-deploy-action\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Deploy static files to AWS S3 with CloudFront invalidation\",\n  \"main\": \"dist/index.js\",\n  \"scripts\": {\n    \"build\": \"ncc build src/index.ts -o dist --source-map\",\n    \"build:watch\": \"ncc build src/index.ts -o dist --source-map --watch\",\n    \"test\": \"jest\",\n    \"test:watch\": \"jest --watch\",\n    \"test:coverage\": \"jest --coverage\",\n    \"lint\": \"eslint src/**/*.ts\",\n    \"lint:fix\": \"eslint src/**/*.ts --fix\",\n    \"format\": \"prettier --write src/**/*.ts\",\n    \"format:check\": \"prettier --check src/**/*.ts\",\n    \"type-check\": \"tsc --noEmit\",\n    \"package\": \"npm run build && npm run package:zip\",\n    \"package:zip\": \"zip -r action.zip dist/ action.yml README.md\",\n    \"release\": \"semantic-release\"\n  },\n  \"repository\": {\n    \"type\": \"git\",\n    \"url\": \"git+https://github.com/username/aws-s3-deploy-action.git\"\n  },\n  \"keywords\": [\n    \"github-actions\",\n    \"aws\",\n    \"s3\",\n    \"cloudfront\",\n    \"deployment\",\n    \"static-files\"\n  ],\n  \"author\": \"Your Name\",\n  \"license\": \"MIT\",\n  \"bugs\": {\n    \"url\": \"https://github.com/username/aws-s3-deploy-action/issues\"\n  },\n  \"homepage\": \"https://github.com/username/aws-s3-deploy-action#readme\",\n  \"dependencies\": {\n    \"@actions/core\": \"^1.10.0\",\n    \"@actions/github\": \"^5.1.1\",\n    \"@aws-sdk/client-s3\": \"^3.400.0\",\n    \"@aws-sdk/client-cloudfront\": \"^3.400.0\",\n    \"@aws-sdk/lib-storage\": \"^3.400.0\",\n    \"glob\": \"^8.1.0\",\n    \"mime-types\": \"^2.1.35\"\n  },\n  \"devDependencies\": {\n    \"@types/jest\": \"^29.5.5\",\n    \"@types/mime-types\": \"^2.1.1\",\n    \"@types/node\": \"^18.17.0\",\n    \"@typescript-eslint/eslint-plugin\": \"^6.7.0\",\n    \"@typescript-eslint/parser\": \"^6.7.0\",\n    \"@vercel/ncc\": \"^0.38.0\",\n    \"eslint\": \"^8.49.0\",\n    \"eslint-config-prettier\": \"^9.0.0\",\n    \"eslint-plugin-jest\": \"^27.4.0\",\n    \"jest\": \"^29.7.0\",\n    \"prettier\": \"^3.0.3\",\n    \"semantic-release\": \"^21.1.0\",\n    \"ts-jest\": \"^29.1.1\",\n    \"typescript\": \"^5.2.2\"\n  }\n}\n\n---\n\n# 3. TypeScript Action Implementation (src/index.ts)\nimport * as core from '@actions/core';\nimport * as github from '@actions/github';\nimport { S3Client, PutObjectCommand, HeadObjectCommand } from '@aws-sdk/client-s3';\nimport { CloudFrontClient, CreateInvalidationCommand } from '@aws-sdk/client-cloudfront';\nimport { Upload } from '@aws-sdk/lib-storage';\nimport { glob } from 'glob';\nimport * as fs from 'fs';\nimport * as path from 'path';\nimport * as mime from 'mime-types';\n\ninterface ActionInputs {\n  awsAccessKeyId: string;\n  awsSecretAccessKey: string;\n  awsRegion: string;\n  s3Bucket: string;\n  sourceDir: string;\n  cloudfrontDistributionId?: string;\n  cacheControl: string;\n  excludePatterns: string[];\n  dryRun: boolean;\n}\n\ninterface UploadResult {\n  uploadedFiles: number;\n  s3Url: string;\n  cloudfrontUrl?: string;\n  invalidationId?: string;\n}\n\nclass S3DeployAction {\n  private s3Client: S3Client;\n  private cloudfrontClient: CloudFrontClient;\n  private inputs: ActionInputs;\n\n  constructor(inputs: ActionInputs) {\n    this.inputs = inputs;\n    \n    // Configure AWS clients\n    const awsConfig = {\n      region: inputs.awsRegion,\n      credentials: {\n        accessKeyId: inputs.awsAccessKeyId,\n        secretAccessKey: inputs.awsSecretAccessKey,\n      },\n    };\n    \n    this.s3Client = new S3Client(awsConfig);\n    this.cloudfrontClient = new CloudFrontClient(awsConfig);\n  }\n\n  async run(): Promise<UploadResult> {\n    try {\n      core.info(`üöÄ Starting S3 deployment...`);\n      core.info(`Source: ${this.inputs.sourceDir}`);\n      core.info(`Bucket: ${this.inputs.s3Bucket}`);\n      core.info(`Region: ${this.inputs.awsRegion}`);\n      core.info(`Dry run: ${this.inputs.dryRun}`);\n\n      // Get files to upload\n      const files = await this.getFilesToUpload();\n      core.info(`üìÅ Found ${files.length} files to upload`);\n\n      if (this.inputs.dryRun) {\n        core.info('üîç Dry run mode - showing files that would be uploaded:');\n        files.forEach(file => {\n          core.info(`  üìÑ ${file.localPath} ‚Üí s3://${this.inputs.s3Bucket}/${file.s3Key}`);\n        });\n        return {\n          uploadedFiles: files.length,\n          s3Url: `https://${this.inputs.s3Bucket}.s3.${this.inputs.awsRegion}.amazonaws.com`,\n        };\n      }\n\n      // Upload files\n      const uploadedCount = await this.uploadFiles(files);\n      \n      // Generate URLs\n      const s3Url = `https://${this.inputs.s3Bucket}.s3.${this.inputs.awsRegion}.amazonaws.com`;\n      let cloudfrontUrl: string | undefined;\n      let invalidationId: string | undefined;\n\n      // CloudFront invalidation\n      if (this.inputs.cloudfrontDistributionId) {\n        cloudfrontUrl = `https://${this.inputs.cloudfrontDistributionId}.cloudfront.net`;\n        invalidationId = await this.invalidateCloudFront();\n      }\n\n      core.info(`‚úÖ Deployment completed successfully!`);\n      core.info(`üìä Uploaded ${uploadedCount} files`);\n      core.info(`üåê S3 URL: ${s3Url}`);\n      if (cloudfrontUrl) {\n        core.info(`‚òÅÔ∏è CloudFront URL: ${cloudfrontUrl}`);\n      }\n\n      return {\n        uploadedFiles: uploadedCount,\n        s3Url,\n        cloudfrontUrl,\n        invalidationId,\n      };\n    } catch (error) {\n      core.setFailed(`Deployment failed: ${error instanceof Error ? error.message : String(error)}`);\n      throw error;\n    }\n  }\n\n  private async getFilesToUpload(): Promise<Array<{ localPath: string; s3Key: string }>> {\n    const sourceDir = path.resolve(this.inputs.sourceDir);\n    \n    if (!fs.existsSync(sourceDir)) {\n      throw new Error(`Source directory does not exist: ${sourceDir}`);\n    }\n\n    // Build glob patterns\n    const includePattern = path.join(sourceDir, '**/*');\n    const excludePatterns = this.inputs.excludePatterns.map(pattern => \n      path.join(sourceDir, pattern)\n    );\n\n    // Find all files\n    const allFiles = await glob(includePattern, {\n      ignore: excludePatterns,\n      nodir: true,\n    });\n\n    return allFiles.map(filePath => ({\n      localPath: filePath,\n      s3Key: path.relative(sourceDir, filePath).replace(/\\\\/g, '/'),\n    }));\n  }\n\n  private async uploadFiles(files: Array<{ localPath: string; s3Key: string }>): Promise<number> {\n    let uploadedCount = 0;\n    const concurrency = 10; // Parallel uploads\n    \n    // Process files in batches\n    for (let i = 0; i < files.length; i += concurrency) {\n      const batch = files.slice(i, i + concurrency);\n      const promises = batch.map(file => this.uploadFile(file));\n      \n      const results = await Promise.allSettled(promises);\n      \n      results.forEach((result, index) => {\n        const file = batch[index];\n        if (result.status === 'fulfilled' && result.value) {\n          uploadedCount++;\n          core.info(`‚úÖ ${file.s3Key}`);\n        } else {\n          core.warning(`‚ùå Failed to upload ${file.s3Key}: ${result.status === 'rejected' ? result.reason : 'Unknown error'}`);\n        }\n      });\n    }\n\n    return uploadedCount;\n  }\n\n  private async uploadFile(file: { localPath: string; s3Key: string }): Promise<boolean> {\n    try {\n      const fileStats = fs.statSync(file.localPath);\n      const fileStream = fs.createReadStream(file.localPath);\n      const contentType = mime.lookup(file.localPath) || 'application/octet-stream';\n\n      // Check if file already exists and has same size\n      try {\n        const headResult = await this.s3Client.send(\n          new HeadObjectCommand({\n            Bucket: this.inputs.s3Bucket,\n            Key: file.s3Key,\n          })\n        );\n        \n        if (headResult.ContentLength === fileStats.size) {\n          core.debug(`‚è≠Ô∏è Skipping ${file.s3Key} (unchanged)`);\n          return true;\n        }\n      } catch {\n        // File doesn't exist, continue with upload\n      }\n\n      // Upload file\n      const upload = new Upload({\n        client: this.s3Client,\n        params: {\n          Bucket: this.inputs.s3Bucket,\n          Key: file.s3Key,\n          Body: fileStream,\n          ContentType: contentType,\n          CacheControl: this.inputs.cacheControl,\n          Metadata: {\n            'uploaded-by': 'github-actions',\n            'upload-time': new Date().toISOString(),\n            'commit-sha': github.context.sha,\n          },\n        },\n      });\n\n      await upload.done();\n      return true;\n    } catch (error) {\n      core.error(`Failed to upload ${file.s3Key}: ${error}`);\n      return false;\n    }\n  }\n\n  private async invalidateCloudFront(): Promise<string | undefined> {\n    if (!this.inputs.cloudfrontDistributionId) {\n      return undefined;\n    }\n\n    try {\n      core.info('‚òÅÔ∏è Creating CloudFront invalidation...');\n      \n      const result = await this.cloudfrontClient.send(\n        new CreateInvalidationCommand({\n          DistributionId: this.inputs.cloudfrontDistributionId,\n          InvalidationBatch: {\n            Paths: {\n              Quantity: 1,\n              Items: ['/*'],\n            },\n            CallerReference: `github-actions-${Date.now()}`,\n          },\n        })\n      );\n\n      const invalidationId = result.Invalidation?.Id;\n      if (invalidationId) {\n        core.info(`‚úÖ CloudFront invalidation created: ${invalidationId}`);\n      }\n      \n      return invalidationId;\n    } catch (error) {\n      core.warning(`Failed to create CloudFront invalidation: ${error}`);\n      return undefined;\n    }\n  }\n}\n\n// Action entry point\nasync function run(): Promise<void> {\n  try {\n    // Parse inputs\n    const inputs: ActionInputs = {\n      awsAccessKeyId: core.getInput('aws-access-key-id', { required: true }),\n      awsSecretAccessKey: core.getInput('aws-secret-access-key', { required: true }),\n      awsRegion: core.getInput('aws-region', { required: true }),\n      s3Bucket: core.getInput('s3-bucket', { required: true }),\n      sourceDir: core.getInput('source-dir', { required: true }),\n      cloudfrontDistributionId: core.getInput('cloudfront-distribution-id') || undefined,\n      cacheControl: core.getInput('cache-control') || 'public, max-age=3600',\n      excludePatterns: core.getInput('exclude-patterns')\n        .split('\\n')\n        .map(p => p.trim())\n        .filter(p => p.length > 0),\n      dryRun: core.getInput('dry-run') === 'true',\n    };\n\n    // Validate inputs\n    if (!fs.existsSync(inputs.sourceDir)) {\n      throw new Error(`Source directory does not exist: ${inputs.sourceDir}`);\n    }\n\n    // Run deployment\n    const action = new S3DeployAction(inputs);\n    const result = await action.run();\n\n    // Set outputs\n    core.setOutput('uploaded-files', result.uploadedFiles.toString());\n    core.setOutput('s3-url', result.s3Url);\n    if (result.cloudfrontUrl) {\n      core.setOutput('cloudfront-url', result.cloudfrontUrl);\n    }\n    if (result.invalidationId) {\n      core.setOutput('invalidation-id', result.invalidationId);\n    }\n\n    // Add job summary\n    await core.summary\n      .addHeading('üöÄ S3 Deployment Summary')\n      .addTable([\n        [{data: 'Files Uploaded', header: true}, result.uploadedFiles.toString()],\n        [{data: 'S3 URL', header: true}, result.s3Url],\n        ...(result.cloudfrontUrl ? [[{data: 'CloudFront URL', header: true}, result.cloudfrontUrl]] : []),\n        ...(result.invalidationId ? [[{data: 'Invalidation ID', header: true}, result.invalidationId]] : []),\n      ])\n      .write();\n\n  } catch (error) {\n    core.setFailed(error instanceof Error ? error.message : String(error));\n  }\n}\n\n// Only run if this is the main module\nif (require.main === module) {\n  run();\n}\n\nexport { run, S3DeployAction, ActionInputs, UploadResult };\n\n---\n\n# 4. Test Suite (src/__tests__/index.test.ts)\nimport { run, S3DeployAction } from '../index';\nimport * as core from '@actions/core';\nimport * as fs from 'fs';\nimport * as path from 'path';\n\n// Mock dependencies\njest.mock('@actions/core');\njest.mock('@aws-sdk/client-s3');\njest.mock('@aws-sdk/client-cloudfront');\njest.mock('@aws-sdk/lib-storage');\njest.mock('fs');\n\nconst mockCore = core as jest.Mocked<typeof core>;\nconst mockFs = fs as jest.Mocked<typeof fs>;\n\ndescribe('S3 Deploy Action', () => {\n  const mockInputs = {\n    'aws-access-key-id': 'AKIAIOSFODNN7EXAMPLE',\n    'aws-secret-access-key': 'wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY',\n    'aws-region': 'us-east-1',\n    's3-bucket': 'my-test-bucket',\n    'source-dir': './dist',\n    'cloudfront-distribution-id': 'E1234567890',\n    'cache-control': 'public, max-age=3600',\n    'exclude-patterns': '*.map\\n*.log',\n    'dry-run': 'false',\n  };\n\n  beforeEach(() => {\n    jest.clearAllMocks();\n    \n    // Setup default mocks\n    mockCore.getInput.mockImplementation((name) => mockInputs[name] || '');\n    mockFs.existsSync.mockReturnValue(true);\n    mockFs.statSync.mockReturnValue({ size: 1024 } as any);\n    mockFs.createReadStream.mockReturnValue({} as any);\n  });\n\n  describe('Input validation', () => {\n    it('should throw error for missing required inputs', async () => {\n      mockCore.getInput.mockImplementation((name) => {\n        if (name === 'aws-access-key-id') return '';\n        return mockInputs[name] || '';\n      });\n\n      await run();\n      \n      expect(mockCore.setFailed).toHaveBeenCalledWith(\n        expect.stringContaining('Input required and not supplied')\n      );\n    });\n\n    it('should throw error for non-existent source directory', async () => {\n      mockFs.existsSync.mockReturnValue(false);\n\n      await run();\n      \n      expect(mockCore.setFailed).toHaveBeenCalledWith(\n        expect.stringContaining('Source directory does not exist')\n      );\n    });\n  });\n\n  describe('File processing', () => {\n    it('should handle dry run mode', async () => {\n      mockCore.getInput.mockImplementation((name) => {\n        if (name === 'dry-run') return 'true';\n        return mockInputs[name] || '';\n      });\n\n      // Mock glob to return some files\n      jest.doMock('glob', () => ({\n        glob: jest.fn().mockResolvedValue(['./dist/index.html', './dist/app.js']),\n      }));\n\n      await run();\n      \n      expect(mockCore.info).toHaveBeenCalledWith(\n        expect.stringContaining('Dry run mode')\n      );\n      expect(mockCore.setOutput).toHaveBeenCalledWith('uploaded-files', '2');\n    });\n  });\n\n  describe('AWS Integration', () => {\n    it('should configure AWS clients correctly', () => {\n      const action = new S3DeployAction({\n        awsAccessKeyId: 'test-key',\n        awsSecretAccessKey: 'test-secret',\n        awsRegion: 'us-west-2',\n        s3Bucket: 'test-bucket',\n        sourceDir: './test',\n        cacheControl: 'no-cache',\n        excludePatterns: [],\n        dryRun: false,\n      });\n\n      expect(action).toBeDefined();\n    });\n  });\n\n  describe('Output generation', () => {\n    it('should set correct outputs after successful deployment', async () => {\n      // Mock successful deployment\n      jest.doMock('glob', () => ({\n        glob: jest.fn().mockResolvedValue(['./dist/index.html']),\n      }));\n\n      await run();\n      \n      expect(mockCore.setOutput).toHaveBeenCalledWith('uploaded-files', expect.any(String));\n      expect(mockCore.setOutput).toHaveBeenCalledWith('s3-url', expect.stringContaining('amazonaws.com'));\n      expect(mockCore.summary.addHeading).toHaveBeenCalledWith(\n        expect.stringContaining('S3 Deployment Summary')\n      );\n    });\n  });\n});\n\n---\n\n# 5. GitHub Workflow for Action Testing (.github/workflows/test-action.yml)\nname: üß™ Test Action\n\non:\n  push:\n    branches: [main, develop]\n  pull_request:\n    branches: [main]\n  workflow_dispatch:\n\njobs:\n  test:\n    name: üî¨ Unit Tests\n    runs-on: ubuntu-latest\n    \n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      \n      - name: Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: '18'\n          cache: 'npm'\n      \n      - name: Install dependencies\n        run: npm ci\n      \n      - name: Lint\n        run: npm run lint\n      \n      - name: Type check\n        run: npm run type-check\n      \n      - name: Unit tests\n        run: npm run test:coverage\n      \n      - name: Upload coverage\n        uses: codecov/codecov-action@v3\n        with:\n          file: ./coverage/lcov.info\n  \n  integration-test:\n    name: üß™ Integration Test\n    runs-on: ubuntu-latest\n    needs: test\n    if: github.event_name == 'push'\n    \n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      \n      - name: Create test files\n        run: |\n          mkdir -p test-files\n          echo '<html><body>Test</body></html>' > test-files/index.html\n          echo 'console.log(\"test\");' > test-files/app.js\n          echo '{\"name\": \"test\"}' > test-files/config.json\n      \n      - name: Test action (dry run)\n        uses: ./\n        with:\n          aws-access-key-id: 'fake-key-id'\n          aws-secret-access-key: 'fake-secret'\n          aws-region: 'us-east-1'\n          s3-bucket: 'test-bucket'\n          source-dir: './test-files'\n          cache-control: 'public, max-age=86400'\n          exclude-patterns: '*.map'\n          dry-run: 'true'\n      \n      - name: Verify outputs\n        run: |\n          echo \"Files would be uploaded: ${{ steps.test.outputs.uploaded-files }}\"\n          echo \"S3 URL: ${{ steps.test.outputs.s3-url }}\"\n  \n  build:\n    name: üì¶ Build Action\n    runs-on: ubuntu-latest\n    needs: test\n    \n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      \n      - name: Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: '18'\n          cache: 'npm'\n      \n      - name: Install dependencies\n        run: npm ci\n      \n      - name: Build action\n        run: npm run build\n      \n      - name: Package action\n        run: npm run package\n      \n      - name: Upload package\n        uses: actions/upload-artifact@v4\n        with:\n          name: action-package\n          path: action.zip\n          retention-days: 30\n  \n  release:\n    name: üöÄ Release Action\n    runs-on: ubuntu-latest\n    needs: [test, integration-test, build]\n    if: github.ref == 'refs/heads/main'\n    \n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n          token: ${{ secrets.GITHUB_TOKEN }}\n      \n      - name: Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: '18'\n          cache: 'npm'\n      \n      - name: Install dependencies\n        run: npm ci\n      \n      - name: Build action\n        run: npm run build\n      \n      - name: Release\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        run: npx semantic-release",
      "language": "typescript",
      "scenario": "Complete JavaScript action development with TypeScript, comprehensive testing, and marketplace publishing workflow"
    },
    {
      "title": "Docker Container Action",
      "description": "Create a Docker-based action with multi-platform support and advanced container features",
      "code": "# Docker Container Action Development\n# Complete setup for containerized action\n\n# 1. Action Metadata (action.yml)\nname: 'Security Scanner'\ndescription: 'Comprehensive security scanning with multiple tools'\nauthor: 'Security Team'\nbranding:\n  icon: 'shield'\n  color: 'red'\n\ninputs:\n  scan-type:\n    description: 'Type of scan to perform'\n    required: true\n    default: 'full'\n    # Options: full, quick, sast, dast, secrets, dependencies\n  \n  target-path:\n    description: 'Path to scan'\n    required: true\n    default: '.'\n  \n  output-format:\n    description: 'Output format'\n    required: false\n    default: 'sarif'\n    # Options: sarif, json, xml, html\n  \n  severity-threshold:\n    description: 'Minimum severity level to report'\n    required: false\n    default: 'medium'\n    # Options: low, medium, high, critical\n  \n  exclude-paths:\n    description: 'Paths to exclude from scanning'\n    required: false\n  \n  config-file:\n    description: 'Custom configuration file path'\n    required: false\n  \n  fail-on-findings:\n    description: 'Fail the action if security issues found'\n    required: false\n    default: 'true'\n  \n  upload-results:\n    description: 'Upload results to GitHub Security tab'\n    required: false\n    default: 'true'\n\noutputs:\n  results-file:\n    description: 'Path to the results file'\n  \n  findings-count:\n    description: 'Number of security findings'\n  \n  highest-severity:\n    description: 'Highest severity level found'\n  \n  scan-duration:\n    description: 'Scan duration in seconds'\n  \n  report-url:\n    description: 'URL to detailed report'\n\nruns:\n  using: 'docker'\n  image: 'Dockerfile'\n  env:\n    SCAN_TYPE: ${{ inputs.scan-type }}\n    TARGET_PATH: ${{ inputs.target-path }}\n    OUTPUT_FORMAT: ${{ inputs.output-format }}\n    SEVERITY_THRESHOLD: ${{ inputs.severity-threshold }}\n    EXCLUDE_PATHS: ${{ inputs.exclude-paths }}\n    CONFIG_FILE: ${{ inputs.config-file }}\n    FAIL_ON_FINDINGS: ${{ inputs.fail-on-findings }}\n    UPLOAD_RESULTS: ${{ inputs.upload-results }}\n\n---\n\n# 2. Multi-stage Dockerfile\nFROM node:18-alpine AS base\n\n# Install system dependencies\nRUN apk add --no-cache \\\n    git \\\n    curl \\\n    bash \\\n    jq \\\n    python3 \\\n    py3-pip \\\n    openssl \\\n    ca-certificates\n\n# Install security tools\nFROM base AS security-tools\n\n# Install Semgrep for SAST\nRUN pip3 install semgrep\n\n# Install Trivy for vulnerability scanning\nRUN curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh | sh -s -- -b /usr/local/bin\n\n# Install GitLeaks for secret scanning\nRUN curl -sSfL https://raw.githubusercontent.com/zricethezav/gitleaks/master/scripts/install.sh | sh\n\n# Install Hadolint for Dockerfile linting\nRUN curl -sL -o /usr/local/bin/hadolint https://github.com/hadolint/hadolint/releases/latest/download/hadolint-Linux-x86_64 \\\n    && chmod +x /usr/local/bin/hadolint\n\n# Install Safety for Python dependency scanning\nRUN pip3 install safety\n\n# Install npm-audit for Node.js dependency scanning\nRUN npm install -g npm-audit-resolver audit-ci\n\n# Install OWASP Dependency Check\nRUN curl -sL https://github.com/jeremylong/DependencyCheck/releases/latest/download/dependency-check-7.4.4-release.zip -o /tmp/dependency-check.zip \\\n    && unzip /tmp/dependency-check.zip -d /opt/ \\\n    && ln -s /opt/dependency-check/bin/dependency-check.sh /usr/local/bin/dependency-check \\\n    && rm /tmp/dependency-check.zip\n\n# Final stage\nFROM security-tools AS final\n\n# Create app directory\nWORKDIR /app\n\n# Copy scanner scripts\nCOPY scripts/ /app/scripts/\nCOPY configs/ /app/configs/\n\n# Make scripts executable\nRUN chmod +x /app/scripts/*.sh\n\n# Set entrypoint\nENTRYPOINT [\"/app/scripts/entrypoint.sh\"]\n\n---\n\n# 3. Main Scanner Script (scripts/entrypoint.sh)\n#!/bin/bash\nset -e\n\n# Configuration\nSCAN_TYPE=${SCAN_TYPE:-\"full\"}\nTARGET_PATH=${TARGET_PATH:-\".\"}\nOUTPUT_FORMAT=${OUTPUT_FORMAT:-\"sarif\"}\nSEVERITY_THRESHOLD=${SEVERITY_THRESHOLD:-\"medium\"}\nEXCLUDE_PATHS=${EXCLUDE_PATHS:-\"\"}\nCONFIG_FILE=${CONFIG_FILE:-\"\"}\nFAIL_ON_FINDINGS=${FAIL_ON_FINDINGS:-\"true\"}\nUPLOAD_RESULTS=${UPLOAD_RESULTS:-\"true\"}\n\n# Output directory\nOUTPUT_DIR=\"/github/workspace/security-scan-results\"\nmkdir -p \"$OUTPUT_DIR\"\n\n# Logging function\nlog() {\n    echo \"[$(date +'%Y-%m-%d %H:%M:%S')] $*\" >&2\n}\n\n# Error handling\nerror_exit() {\n    log \"ERROR: $1\"\n    exit 1\n}\n\n# Start time\nSTART_TIME=$(date +%s)\n\nlog \"üõ°Ô∏è Starting Security Scanner\"\nlog \"Scan Type: $SCAN_TYPE\"\nlog \"Target Path: $TARGET_PATH\"\nlog \"Output Format: $OUTPUT_FORMAT\"\nlog \"Severity Threshold: $SEVERITY_THRESHOLD\"\n\n# Initialize counters\nTOTAL_FINDINGS=0\nHIGHEST_SEVERITY=\"info\"\n\n# Function to update severity\nupdate_severity() {\n    local new_severity=$1\n    case \"$new_severity\" in\n        \"critical\")\n            HIGHEST_SEVERITY=\"critical\"\n            ;;\n        \"high\")\n            if [[ \"$HIGHEST_SEVERITY\" != \"critical\" ]]; then\n                HIGHEST_SEVERITY=\"high\"\n            fi\n            ;;\n        \"medium\")\n            if [[ \"$HIGHEST_SEVERITY\" != \"critical\" && \"$HIGHEST_SEVERITY\" != \"high\" ]]; then\n                HIGHEST_SEVERITY=\"medium\"\n            fi\n            ;;\n        \"low\")\n            if [[ \"$HIGHEST_SEVERITY\" == \"info\" ]]; then\n                HIGHEST_SEVERITY=\"low\"\n            fi\n            ;;\n    esac\n}\n\n# Function to run SAST scanning\nrun_sast_scan() {\n    log \"üîç Running SAST scan with Semgrep...\"\n    \n    local output_file=\"$OUTPUT_DIR/sast-results.$OUTPUT_FORMAT\"\n    local semgrep_args=(\"--config=auto\" \"--json\" \"--output=$output_file\")\n    \n    if [[ -n \"$CONFIG_FILE\" && -f \"$CONFIG_FILE\" ]]; then\n        semgrep_args+=(\"--config=$CONFIG_FILE\")\n    fi\n    \n    if [[ -n \"$EXCLUDE_PATHS\" ]]; then\n        IFS=',' read -ra EXCLUDE_ARRAY <<< \"$EXCLUDE_PATHS\"\n        for exclude in \"${EXCLUDE_ARRAY[@]}\"; do\n            semgrep_args+=(\"--exclude=$exclude\")\n        done\n    fi\n    \n    if semgrep \"${semgrep_args[@]}\" \"$TARGET_PATH\"; then\n        local findings_count\n        findings_count=$(jq '.results | length' \"$output_file\" 2>/dev/null || echo \"0\")\n        TOTAL_FINDINGS=$((TOTAL_FINDINGS + findings_count))\n        log \"‚úÖ SAST scan completed. Found $findings_count issues.\"\n    else\n        log \"‚ö†Ô∏è SAST scan completed with errors.\"\n    fi\n}\n\n# Function to run dependency scanning\nrun_dependency_scan() {\n    log \"üì¶ Running dependency vulnerability scan...\"\n    \n    local output_file=\"$OUTPUT_DIR/dependencies-results.$OUTPUT_FORMAT\"\n    \n    # Scan for different package managers\n    if [[ -f \"$TARGET_PATH/package.json\" ]]; then\n        log \"Scanning Node.js dependencies...\"\n        cd \"$TARGET_PATH\"\n        npm audit --json > \"$output_file.npm\" 2>/dev/null || true\n        cd - > /dev/null\n    fi\n    \n    if [[ -f \"$TARGET_PATH/requirements.txt\" ]]; then\n        log \"Scanning Python dependencies...\"\n        safety check --json --file=\"$TARGET_PATH/requirements.txt\" > \"$output_file.python\" 2>/dev/null || true\n    fi\n    \n    if [[ -f \"$TARGET_PATH/go.mod\" ]]; then\n        log \"Scanning Go dependencies...\"\n        cd \"$TARGET_PATH\"\n        go list -json -deps ./... | nancy sleuth > \"$output_file.go\" 2>/dev/null || true\n        cd - > /dev/null\n    fi\n    \n    # Use Trivy for comprehensive scanning\n    trivy fs --format json --output \"$output_file.trivy\" \"$TARGET_PATH\" || true\n    \n    log \"‚úÖ Dependency scan completed.\"\n}\n\n# Function to run secret scanning\nrun_secret_scan() {\n    log \"üîê Running secret scan with GitLeaks...\"\n    \n    local output_file=\"$OUTPUT_DIR/secrets-results.$OUTPUT_FORMAT\"\n    \n    if gitleaks detect --source=\"$TARGET_PATH\" --report-format=json --report-path=\"$output_file\" --no-git; then\n        log \"‚úÖ Secret scan completed. No secrets found.\"\n    else\n        local findings_count\n        findings_count=$(jq '. | length' \"$output_file\" 2>/dev/null || echo \"0\")\n        TOTAL_FINDINGS=$((TOTAL_FINDINGS + findings_count))\n        update_severity \"high\"  # Secrets are typically high severity\n        log \"‚ö†Ô∏è Secret scan found $findings_count potential secrets.\"\n    fi\n}\n\n# Function to run infrastructure scanning\nrun_infrastructure_scan() {\n    log \"üèóÔ∏è Running infrastructure scan...\"\n    \n    local output_file=\"$OUTPUT_DIR/infrastructure-results.$OUTPUT_FORMAT\"\n    \n    # Scan Dockerfiles\n    find \"$TARGET_PATH\" -name \"Dockerfile*\" -type f | while read -r dockerfile; do\n        log \"Scanning Dockerfile: $dockerfile\"\n        hadolint \"$dockerfile\" --format json >> \"$output_file.hadolint\" 2>/dev/null || true\n    done\n    \n    # Scan Terraform files\n    if find \"$TARGET_PATH\" -name \"*.tf\" -type f | grep -q .; then\n        log \"Scanning Terraform files...\"\n        # Add Terraform scanning logic here\n    fi\n    \n    # Scan Kubernetes manifests\n    if find \"$TARGET_PATH\" -name \"*.yaml\" -o -name \"*.yml\" | grep -q .; then\n        log \"Scanning Kubernetes manifests...\"\n        # Add Kubernetes scanning logic here\n    fi\n    \n    log \"‚úÖ Infrastructure scan completed.\"\n}\n\n# Function to convert results to SARIF format\nconvert_to_sarif() {\n    log \"üìÑ Converting results to SARIF format...\"\n    \n    local sarif_file=\"$OUTPUT_DIR/security-results.sarif\"\n    \n    # Create basic SARIF structure\n    cat > \"$sarif_file\" << EOF\n{\n  \"\\$schema\": \"https://raw.githubusercontent.com/oasis-tcs/sarif-spec/master/Schemata/sarif-schema-2.1.0.json\",\n  \"version\": \"2.1.0\",\n  \"runs\": [\n    {\n      \"tool\": {\n        \"driver\": {\n          \"name\": \"Security Scanner Action\",\n          \"version\": \"1.0.0\",\n          \"informationUri\": \"https://github.com/your-org/security-scanner-action\"\n        }\n      },\n      \"results\": []\n    }\n  ]\n}\nEOF\n    \n    # Merge all scan results into SARIF format\n    python3 /app/scripts/convert_to_sarif.py \"$OUTPUT_DIR\" \"$sarif_file\"\n    \n    log \"‚úÖ SARIF conversion completed.\"\n}\n\n# Function to generate HTML report\ngenerate_html_report() {\n    log \"üìä Generating HTML report...\"\n    \n    local html_file=\"$OUTPUT_DIR/security-report.html\"\n    \n    python3 /app/scripts/generate_html_report.py \"$OUTPUT_DIR\" \"$html_file\"\n    \n    log \"‚úÖ HTML report generated: $html_file\"\n}\n\n# Main scanning logic\ncase \"$SCAN_TYPE\" in\n    \"full\")\n        run_sast_scan\n        run_dependency_scan\n        run_secret_scan\n        run_infrastructure_scan\n        ;;\n    \"quick\")\n        run_sast_scan\n        run_secret_scan\n        ;;\n    \"sast\")\n        run_sast_scan\n        ;;\n    \"dependencies\")\n        run_dependency_scan\n        ;;\n    \"secrets\")\n        run_secret_scan\n        ;;\n    \"infrastructure\")\n        run_infrastructure_scan\n        ;;\n    *)\n        error_exit \"Unknown scan type: $SCAN_TYPE\"\n        ;;\nesac\n\n# Convert results based on output format\ncase \"$OUTPUT_FORMAT\" in\n    \"sarif\")\n        convert_to_sarif\n        RESULTS_FILE=\"$OUTPUT_DIR/security-results.sarif\"\n        ;;\n    \"html\")\n        generate_html_report\n        RESULTS_FILE=\"$OUTPUT_DIR/security-report.html\"\n        ;;\n    \"json\")\n        # JSON results are already generated by individual tools\n        RESULTS_FILE=\"$OUTPUT_DIR/combined-results.json\"\n        ;;\n    *)\n        RESULTS_FILE=\"$OUTPUT_DIR/security-results.sarif\"\n        ;;\nesac\n\n# Calculate scan duration\nEND_TIME=$(date +%s)\nSCAN_DURATION=$((END_TIME - START_TIME))\n\n# Set outputs\necho \"results-file=$RESULTS_FILE\" >> \"$GITHUB_OUTPUT\"\necho \"findings-count=$TOTAL_FINDINGS\" >> \"$GITHUB_OUTPUT\"\necho \"highest-severity=$HIGHEST_SEVERITY\" >> \"$GITHUB_OUTPUT\"\necho \"scan-duration=$SCAN_DURATION\" >> \"$GITHUB_OUTPUT\"\necho \"report-url=file://$RESULTS_FILE\" >> \"$GITHUB_OUTPUT\"\n\n# Summary\nlog \"üéØ Scan Summary:\"\nlog \"   Total Findings: $TOTAL_FINDINGS\"\nlog \"   Highest Severity: $HIGHEST_SEVERITY\"\nlog \"   Scan Duration: ${SCAN_DURATION}s\"\nlog \"   Results File: $RESULTS_FILE\"\n\n# Upload results to GitHub Security tab\nif [[ \"$UPLOAD_RESULTS\" == \"true\" && \"$OUTPUT_FORMAT\" == \"sarif\" ]]; then\n    log \"üì§ Uploading results to GitHub Security tab...\"\n    # This would be handled by the workflow using github/codeql-action/upload-sarif\nfi\n\n# Check if we should fail on findings\nif [[ \"$FAIL_ON_FINDINGS\" == \"true\" && $TOTAL_FINDINGS -gt 0 ]]; then\n    # Check severity threshold\n    case \"$SEVERITY_THRESHOLD\" in\n        \"low\")\n            if [[ \"$HIGHEST_SEVERITY\" != \"info\" ]]; then\n                error_exit \"Security findings found above threshold: $HIGHEST_SEVERITY\"\n            fi\n            ;;\n        \"medium\")\n            if [[ \"$HIGHEST_SEVERITY\" == \"high\" || \"$HIGHEST_SEVERITY\" == \"critical\" ]]; then\n                error_exit \"Security findings found above threshold: $HIGHEST_SEVERITY\"\n            fi\n            ;;\n        \"high\")\n            if [[ \"$HIGHEST_SEVERITY\" == \"critical\" ]]; then\n                error_exit \"Security findings found above threshold: $HIGHEST_SEVERITY\"\n            fi\n            ;;\n        \"critical\")\n            # Only fail on critical findings\n            ;;\n    esac\nfi\n\nlog \"‚úÖ Security scan completed successfully!\"\n\n---\n\n# 4. Usage Example (.github/workflows/security-scan.yml)\nname: üõ°Ô∏è Security Scan\n\non:\n  push:\n    branches: [main, develop]\n  pull_request:\n    branches: [main]\n  schedule:\n    - cron: '0 2 * * *'  # Daily scan\n\njobs:\n  security-scan:\n    name: üîç Comprehensive Security Scan\n    runs-on: ubuntu-latest\n    \n    permissions:\n      contents: read\n      security-events: write\n      actions: read\n    \n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 0  # Full history for secret scanning\n      \n      - name: Run Security Scanner\n        id: security-scan\n        uses: your-org/security-scanner-action@v1\n        with:\n          scan-type: 'full'\n          target-path: '.'\n          output-format: 'sarif'\n          severity-threshold: 'medium'\n          exclude-paths: 'node_modules,dist,*.test.js'\n          fail-on-findings: 'true'\n          upload-results: 'true'\n      \n      - name: Upload SARIF results\n        if: always()\n        uses: github/codeql-action/upload-sarif@v2\n        with:\n          sarif_file: ${{ steps.security-scan.outputs.results-file }}\n      \n      - name: Upload detailed report\n        if: always()\n        uses: actions/upload-artifact@v4\n        with:\n          name: security-scan-report\n          path: security-scan-results/\n          retention-days: 30\n      \n      - name: Comment PR with results\n        if: github.event_name == 'pull_request'\n        uses: actions/github-script@v7\n        with:\n          script: |\n            const { data: comments } = await github.rest.issues.listComments({\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              issue_number: context.issue.number,\n            });\n            \n            const botComment = comments.find(comment => \n              comment.user.login === 'github-actions[bot]' && \n              comment.body.includes('üõ°Ô∏è Security Scan Results')\n            );\n            \n            const body = `## üõ°Ô∏è Security Scan Results\n            \n            **Findings:** ${{ steps.security-scan.outputs.findings-count }}\n            **Highest Severity:** ${{ steps.security-scan.outputs.highest-severity }}\n            **Scan Duration:** ${{ steps.security-scan.outputs.scan-duration }}s\n            **Report:** [View Details](${{ steps.security-scan.outputs.report-url }})\n            \n            ${parseInt('${{ steps.security-scan.outputs.findings-count }}') > 0 ? '‚ö†Ô∏è Security issues found! Please review the detailed report.' : '‚úÖ No security issues found!'}`;\n            \n            if (botComment) {\n              await github.rest.issues.updateComment({\n                owner: context.repo.owner,\n                repo: context.repo.repo,\n                comment_id: botComment.id,\n                body: body\n              });\n            } else {\n              await github.rest.issues.createComment({\n                owner: context.repo.owner,\n                repo: context.repo.repo,\n                issue_number: context.issue.number,\n                body: body\n              });\n            }",
      "language": "bash",
      "scenario": "Comprehensive Docker-based security scanner action with multiple scanning tools and detailed reporting capabilities"
    }
  ],
  "troubleshooting": [
    {
      "problem": "Action not found in marketplace after publishing",
      "solution": "Check action.yml syntax, ensure proper repository structure, and verify marketplace publishing requirements",
      "commands": ["gh api repos/:owner/:repo", "yamllint action.yml", "gh release create v1.0.0"],
      "details": "Actions must be in public repositories with proper action.yml metadata and semantic versioning"
    },
    {
      "problem": "Docker action failing with 'exec format error'",
      "solution": "Build Docker image for correct architecture and ensure executable permissions",
      "commands": ["docker build --platform linux/amd64", "chmod +x entrypoint.sh", "docker run --platform linux/amd64"],
      "details": "GitHub Actions runners use linux/amd64 architecture; ensure Docker images are built accordingly"
    },
    {
      "problem": "Action inputs not being passed correctly",
      "solution": "Verify action.yml input definitions match usage and check input parsing in action code",
      "commands": ["core.getInput('input-name')", "console.log(process.env.INPUT_NAME)", "echo $INPUT_NAME"],
      "details": "Input names are converted to uppercase with dashes replaced by underscores in environment variables"
    },
    {
      "problem": "Composite action steps not executing in correct order",
      "solution": "Use proper step dependencies and check shell configuration for composite actions",
      "commands": ["runs: { using: 'composite' }", "shell: bash", "if: steps.previous.outcome == 'success'"],
      "details": "Composite actions require explicit shell specification and proper step dependencies"
    },
    {
      "problem": "Action failing to set outputs correctly",
      "solution": "Use proper output syntax and ensure outputs are set before action completion",
      "commands": ["echo 'result=value' >> $GITHUB_OUTPUT", "core.setOutput('result', 'value')", "outputs: { result: { value: '${{ steps.step.outputs.result }}' } }"],
      "details": "Outputs must be set using GITHUB_OUTPUT file or core.setOutput() function"
    }
  ],
  "tags": ["marketplace", "custom-actions", "javascript-actions", "docker-actions", "composite-actions", "action-publishing", "action-development"]
}
